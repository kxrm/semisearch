# Semantic Search CLI Tool

A privacy-first CLI tool for semantic search across local files, built with Rust.

## Current Status: All Core Phases Complete âœ…

All Phases 1, 2, and 3 from the architecture plan have been implemented with comprehensive test coverage!

### âœ… **Phase 1: Foundation (MVP) - COMPLETED**

1. **âœ… CLI Interface with Subcommands** - Proper `clap` implementation with:
   - `search` - Search for matches in files
   - `index` - Directory indexing with persistent storage
   - `config` - Configuration and database statistics

2. **âœ… File Traversal** - Using `ignore` crate for:
   - Recursive directory scanning
   - Respects `.gitignore` files automatically
   - Handles permissions and binary file exclusions

3. **âœ… Keyword Search** - Case-insensitive substring matching:
   - Line-by-line processing
   - Proper file type filtering
   - Error handling for unreadable files

4. **âœ… Multiple Output Formats**:
   - Plain text: `file:line:content`
   - JSON: Structured output with metadata

### âœ… **Phase 2: Storage Layer - COMPLETED**

1. **âœ… SQLite Database** - Persistent local storage:
   - Schema with files, chunks, and query cache tables
   - Database stored in `~/.semisearch/index.db`
   - Proper indexes and foreign key constraints
   - Automatic migration system

2. **âœ… Incremental Indexing** - Smart change detection:
   - SHA-256 hash-based file change detection
   - Only processes modified files on re-indexing
   - **920x faster** re-indexing (0.01s vs 9.26s for unchanged files)
   - Configurable exclusion patterns

3. **âœ… File Processing & Storage** - Efficient content management:
   - Text chunking with configurable sizes
   - Metadata tracking (file size, modification time, etc.)
   - Integration with existing Phase 3 text processing
   - Thread-safe operations with proper error handling

4. **âœ… CLI Integration** - Production-ready commands:
   - `semisearch index <directory>` - Index files with progress feedback
   - `semisearch config` - Show database stats and configuration
   - User-friendly error messages and status reporting

### âœ… **Phase 3: Text Processing & Advanced Search - COMPLETED**

**New Modular Architecture:**
- âœ… **Trait-based Search Strategies** - Plugin architecture for extensible search
- âœ… **Text Processing Pipeline** - Comprehensive text analysis and preparation
- âœ… **Multiple Search Algorithms** - Keyword, Fuzzy, Regex, and TF-IDF search
- âœ… **Unicode Support** - Full internationalization and multi-language text processing

**Advanced Text Processing:**
- âœ… **TextProcessor** with configurable chunk lengths and stop words
- âœ… **Language Detection** - Automatic detection of programming languages (Rust, Python, JavaScript, Java, C, HTML, SQL)
- âœ… **Text Complexity Analysis** - Vocabulary diversity and readability scoring
- âœ… **Phrase Extraction** - 2-word and 3-word phrase combinations
- âœ… **Overlapping Chunks** - Better semantic coverage for large files
- âœ… **Unicode-aware Tokenization** - Proper handling of international characters

**Enhanced Search Strategies:**
- âœ… **Keyword Search** - Basic string matching with phrase bonuses and whole word matching
- âœ… **Fuzzy Search** - Multi-algorithm approach with SkimMatcherV2, edit distance, and typo tolerance
- âœ… **Regex Search** - Pattern detection, compilation caching, wildcard support, and complex patterns
- âœ… **TF-IDF Search** - Statistical ranking with document frequency analysis and index building

**Performance & Quality:**
- âœ… **Regex Compilation Caching** - Improved performance for repeated patterns
- âœ… **Parallel Processing Support** - Rayon integration for concurrent operations
- âœ… **Resource Management** - Each strategy specifies its computational requirements
- âœ… **Error Handling** - Comprehensive error handling with detailed messages

## Usage

### Storage & Indexing Commands
```bash
# Index your project for persistent storage
cargo run -- index ./src

# Check database stats and configuration
cargo run -- config

# Re-index (lightning fast with incremental updates)
cargo run -- index ./src
```

### Basic Search Commands
```bash
# Basic keyword search
cargo run -- search "TODO" --path ./src

# JSON output with limit
cargo run -- search "query" --format json --limit 5

# Case-sensitive search
cargo run -- search "TODO" --case-sensitive
```

### Advanced Search Features
```bash
# Fuzzy matching (handles typos and partial matches)
cargo run -- search "TOOD" --fuzzy

# Enhanced typo tolerance with edit distance
cargo run -- search "TODO" --typo-tolerance --max-edit-distance 2

# Regex pattern matching
cargo run -- search "TODO.*:" --regex

# Email pattern matching
cargo run -- search "\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b" --regex

# Wildcard patterns
cargo run -- search "*.txt" --regex

# Combined options with scoring
cargo run -- search "error" --fuzzy --score 0.5 --format json

# Whole word matching
cargo run -- search "test" --whole-words
```

### Available Options
- `--path, -p`: Target directory (default: current directory)
- `--format, -f`: Output format - `plain` or `json` (default: plain)
- `--limit, -l`: Maximum number of results (default: 10)
- `--score, -s`: Minimum similarity score (0.0-1.0, default: 0.0)
- `--fuzzy`: Enable fuzzy matching for typos and partial matches
- `--typo-tolerance`: Enable typo tolerance using edit distance
- `--max-edit-distance`: Maximum edit distance for typos (default: 2)
- `--regex`: Use regex pattern matching
- `--case-sensitive`: Perform case-sensitive search (default: case-insensitive)
- `--whole-words`: Match whole words only (works with regex)

## Architecture

The project follows a modular, trait-based architecture with progressive enhancement and persistent storage:

### Current Module Structure
```
src/
â”œâ”€â”€ main.rs              # CLI interface and command handling
â”œâ”€â”€ lib.rs               # Core library exports
â”œâ”€â”€ core/                # Core functionality
â”‚   â”œâ”€â”€ mod.rs          # Core module exports
â”‚   â””â”€â”€ indexer.rs      # File indexing with change detection
â”œâ”€â”€ storage/             # Persistent storage layer
â”‚   â”œâ”€â”€ mod.rs          # Storage module exports
â”‚   â””â”€â”€ database.rs     # SQLite database integration
â”œâ”€â”€ search/              # Search strategies and algorithms
â”‚   â”œâ”€â”€ mod.rs          # Search engine and trait definitions
â”‚   â”œâ”€â”€ keyword.rs      # Keyword search implementation
â”‚   â”œâ”€â”€ fuzzy.rs        # Fuzzy search with typo tolerance
â”‚   â”œâ”€â”€ regex_search.rs # Regex pattern matching
â”‚   â”œâ”€â”€ tfidf.rs        # TF-IDF statistical ranking
â”‚   â””â”€â”€ strategy.rs     # Helper functions for search strategies
â””â”€â”€ text/               # Text processing pipeline
    â”œâ”€â”€ mod.rs          # Text processing exports
    â”œâ”€â”€ processor.rs    # Main text processing logic
    â””â”€â”€ tokenizer.rs    # Unicode-aware tokenization

migrations/
â””â”€â”€ 001_initial.sql     # Database schema with indexes
```

### Architecture Phases
- **Phase 1: Foundation** âœ… - CLI interface, basic search, file traversal
- **Phase 2: Storage Layer** âœ… - SQLite persistence, incremental indexing, change detection
- **Phase 3: Text Processing** âœ… - Modular architecture, advanced text processing, multiple search strategies
- **Phase 4: Local Embeddings** ðŸ“‹ - Next: ML-based semantic understanding, vector similarity

## Dependencies

### Core Dependencies
- `clap` - Command line argument parsing with derive macros
- `ignore` - Git-aware file traversal (respects .gitignore)
- `serde` + `serde_json` - JSON serialization for output
- `anyhow` - Better error handling and propagation

### Phase 2 Storage Dependencies
- `rusqlite` - SQLite database integration with bundled SQLite
- `sha2` - SHA-256 hashing for file change detection
- `chrono` - Date/time handling for metadata
- `dirs` - Cross-platform user directory detection

### Phase 3 Text Processing Dependencies
- `fuzzy-matcher` - Advanced fuzzy string matching with SkimMatcherV2
- `regex` - Regular expression pattern matching with caching
- `edit-distance` - String similarity calculations
- `unicode-segmentation` - Unicode-aware text processing
- `thiserror` - Custom error types
- `rayon` - Parallel processing capabilities
- `rustc-hash` - High-performance hash maps

### Development Dependencies
- `criterion` - Performance benchmarking and regression testing
- `proptest` - Property-based testing for fuzzy scenarios
- `tempfile` - Temporary file handling for tests

## Testing

### Comprehensive Test Coverage: 120 Tests âœ…

The project maintains industry-standard test coverage with multiple test categories:

#### Core Library Tests (87 tests - 100% passing)
- **Search Module**: 12 tests - strategy registration, options, result merging
- **Text Processor**: 11 tests - all processing methods, language detection, complexity
- **Keyword Search**: 12 tests - scoring, case sensitivity, phrase matching
- **Fuzzy Search**: 15 tests - typo tolerance, edit distance, multi-algorithm scoring
- **Regex Search**: 15 tests - pattern detection, caching, complex patterns
- **TF-IDF Search**: 12 tests - indexing, scoring, statistics
- **Tokenizer**: 6 tests - classification, Unicode handling, position tracking
- **Strategy Helper**: 8 tests - context, merging, highlighting
- **Integration**: 16 tests - cross-module functionality, file processing

#### Integration Tests (8 tests - 100% passing)
- End-to-end search workflows
- File system integration
- Performance testing
- Output format verification
- Case sensitivity handling
- Large directory processing
- Fuzzy and regex search integration

#### Phase 2 Storage Tests (9 tests - 100% passing)
- Database operations and schema
- Incremental indexing with change detection
- File exclusion patterns and size limits
- Text processing integration
- Error handling and edge cases
- End-to-end indexing workflows

#### Phase 3 Comprehensive Tests (19 tests)
- Multi-strategy search coordination
- Text processing comprehensive scenarios
- Language detection across multiple languages
- Performance with large content
- Edge cases and error handling
- File integration scenarios

### Test Categories Covered
- âœ… **Functionality Tests**: All public methods and core features
- âœ… **Edge Case Tests**: Empty inputs, special characters, boundary conditions
- âœ… **Performance Tests**: Large content handling, concurrent access, incremental indexing
- âœ… **Integration Tests**: Multi-strategy coordination, file processing, database operations
- âœ… **Configuration Tests**: All search options and parameters
- âœ… **Error Handling**: Invalid inputs, malformed patterns, database errors
- âœ… **Unicode Tests**: International character support
- âœ… **Concurrent Tests**: Thread safety verification

### Running Tests

```bash
# Run all tests (unit + integration + storage)
cargo test

# Run core library tests only
cargo test --lib

# Run integration tests only
cargo test --test integration_tests

# Run Phase 2 storage tests
cargo test --test phase2_storage_tests

# Run Phase 3 comprehensive tests
cargo test --test phase3_text_processing_tests

# Run with output for debugging
cargo test -- --nocapture

# Run specific test categories
cargo test search::keyword::tests    # Keyword search tests
cargo test storage::database::tests  # Database tests
cargo test core::indexer::tests      # Indexer tests
```

## Performance

### Current Performance Characteristics
- **Startup Time:** < 1s for basic keyword search
- **Indexing Speed:** 29 files in 9.26s (initial), 0.01s (incremental)
- **Search Speed:** Handles thousands of files efficiently with parallel processing
- **Memory Usage:** Minimal memory footprint with efficient data structures
- **Storage:** Efficient SQLite storage (784KB for 30 files, 5,797 chunks)
- **Caching:** Regex compilation caching for improved performance
- **Scalability:** Resource-aware search strategies with configurable limits

### Performance Features
- **Incremental Indexing:** SHA-256 change detection provides 920x speedup for unchanged files
- **Parallel Processing:** Rayon integration for concurrent file processing
- **Efficient Data Structures:** rustc-hash for high-performance hash maps
- **Database Optimization:** Proper indexes and query optimization
- **Regex Caching:** Compiled patterns cached for repeated use
- **Resource Management:** Each search strategy specifies computational requirements
- **Configurable Limits:** Adjustable result limits and scoring thresholds

## Next Steps (Phase 4: Local Embeddings)

Based on the architecture plan, the next features to implement are:

1. **Local Embedding Models**:
   - ONNX Runtime integration for ML inference
   - Vector similarity search capabilities
   - Semantic understanding beyond keyword matching
   - Hybrid search combining traditional and semantic approaches

2. **Enhanced Semantic Features**:
   - Context-aware search results
   - Query expansion and synonym handling
   - Multi-language semantic search
   - Document similarity and clustering

3. **Production Optimizations**:
   - Background file watching for real-time updates
   - Cross-platform optimization
   - Advanced caching strategies
   - Query performance optimization

## CI/CD Pipeline

### GitHub Actions Workflows

- **CI Pipeline** (`.github/workflows/ci.yml`):
  - Multi-platform testing (Linux, Windows, macOS, ARM64)
  - Rust version matrix (stable, beta, MSRV 1.70.0)
  - Security auditing with cargo-audit and cargo-deny
  - Code quality checks (clippy, formatting)
  - Architecture plan compliance validation
  - Storage layer integration tests

- **Release Pipeline** (`.github/workflows/release.yml`):
  - Automated releases on git tags
  - Multi-platform binary builds
  - Crates.io publishing (when configured)
  - Release notes generation

### Status Badges

[![CI](https://github.com/kxrm/semisearch/workflows/CI%2FCD%20Pipeline/badge.svg)](https://github.com/kxrm/semisearch/actions)

## Project Structure

```
src/
â”œâ”€â”€ main.rs              # CLI interface and command handling
â”œâ”€â”€ lib.rs               # Core library exports and integration
â”œâ”€â”€ core/                # Core functionality
â”‚   â”œâ”€â”€ mod.rs          # Core module exports
â”‚   â””â”€â”€ indexer.rs      # File indexing with change detection (418 lines)
â”œâ”€â”€ storage/             # Persistent storage layer
â”‚   â”œâ”€â”€ mod.rs          # Storage module exports
â”‚   â””â”€â”€ database.rs     # SQLite database integration (439 lines)
â”œâ”€â”€ search/              # Search strategies and algorithms
â”‚   â”œâ”€â”€ mod.rs          # Search engine and trait definitions
â”‚   â”œâ”€â”€ keyword.rs      # Keyword search implementation
â”‚   â”œâ”€â”€ fuzzy.rs        # Fuzzy search with typo tolerance
â”‚   â”œâ”€â”€ regex_search.rs # Regex pattern matching
â”‚   â”œâ”€â”€ tfidf.rs        # TF-IDF statistical ranking
â”‚   â””â”€â”€ strategy.rs     # Helper functions for search strategies
â””â”€â”€ text/               # Text processing pipeline
    â”œâ”€â”€ mod.rs          # Text processing exports
    â”œâ”€â”€ processor.rs    # Main text processing logic
    â””â”€â”€ tokenizer.rs    # Unicode-aware tokenization

migrations/
â””â”€â”€ 001_initial.sql     # Database schema with indexes (41 lines)

tests/
â”œâ”€â”€ integration_tests.rs           # End-to-end testing (8 tests)
â”œâ”€â”€ phase2_storage_tests.rs        # Phase 2 storage tests (9 tests)
â”œâ”€â”€ phase3_text_processing_tests.rs # Comprehensive Phase 3 tests (19 tests)
â”œâ”€â”€ run-all.sh                     # Comprehensive test runner
â”œâ”€â”€ test-search.sh                 # Search functionality tests
â”œâ”€â”€ test-performance.sh            # Performance benchmarking
â””â”€â”€ validate-ci.sh                 # CI environment validation

.github/
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ ci.yml              # CI/CD pipeline
â”‚   â””â”€â”€ release.yml         # Release automation
â””â”€â”€ README.md               # CI/CD documentation

docs/
â””â”€â”€ SEMANTIC_SEARCH_ARCHITECTURE_PLAN.md  # Complete technical specification
```

## Key Features Implemented

### Persistent Storage Layer (Phase 2)
- **SQLite Integration**: Complete database schema with files, chunks, and query cache
- **Incremental Indexing**: SHA-256 hash-based change detection for efficiency
- **File Processing**: Integration with Phase 3 text processing pipeline
- **CLI Commands**: `index` and `config` commands for database management
- **Privacy-First**: All data stored locally in `~/.semisearch/index.db`

### Advanced Text Processing (Phase 3)
- **Multi-language Support**: Automatic detection of Rust, Python, JavaScript, Java, C, HTML, SQL
- **Stop Word Filtering**: Customizable stop word lists for better search relevance
- **Phrase Extraction**: Automatic extraction of 2-word and 3-word meaningful phrases
- **Text Complexity Scoring**: Vocabulary diversity analysis for content assessment
- **Overlapping Chunk Processing**: Better semantic coverage for large documents

### Sophisticated Search Algorithms
- **Multi-Algorithm Fuzzy Matching**: SkimMatcherV2, edit distance, and substring bonuses
- **TF-IDF Statistical Ranking**: Document frequency analysis with phrase bonuses
- **Advanced Regex Processing**: Pattern detection, caching, and wildcard support
- **Contextual Scoring**: Position bonuses, length penalties, and relevance factors

### Developer Experience
- **Trait-based Architecture**: Easy to extend with new search strategies
- **Comprehensive Error Handling**: Detailed error messages with context
- **Unicode-aware Processing**: Full internationalization support
- **Performance Monitoring**: Resource requirements and benchmarking capabilities
- **Production Ready**: Comprehensive CLI with persistent storage

This implementation provides a robust foundation for semantic search capabilities, with Phases 1-3 establishing a complete text processing and storage system that seamlessly integrates traditional search algorithms with persistent indexing, ready for the upcoming local embedding features in Phase 4.

## Documentation

- [Architecture Plan](docs/SEMANTIC_SEARCH_ARCHITECTURE_PLAN.md) - Complete technical specification and implementation roadmap
- [CI/CD Documentation](.github/CI.md) - GitHub Actions setup and troubleshooting 